{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import load_data, clean_data, transform_types, create_bins, fill_missing\n",
    "\n",
    "df = load_data('data/clinical_trial_raw.csv')\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"03/28/2023\" doesn't match format \"%Y-%m-%d\", at position 12. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df_transform = df.copy()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Use transform_types() to convert enrollment_date to datetime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_transform = \u001b[43mtransform_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menrollment_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\u001b[39;00m\n\u001b[32m      6\u001b[39m df_transform = transform_types(df_transform, {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msite\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mintervention_group\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msex\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ucsf_courses_resources/fall 2025/ds_217/ds217-midterm-jack-neary/q3_data_utils.py:173\u001b[39m, in \u001b[36mtransform_types\u001b[39m\u001b[34m(df, type_map)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column, target_type \u001b[38;5;129;01min\u001b[39;00m type_map.items():\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m target_type == \u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         df[column] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m target_type == \u001b[33m\"\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    175\u001b[39m         df[column] = pd.to_numeric(df[column])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ucsf_courses_resources/fall 2025/ds_217/ds217-midterm-jack-neary/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1071\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ucsf_courses_resources/fall 2025/ds_217/ds217-midterm-jack-neary/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ucsf_courses_resources/fall 2025/ds_217/ds217-midterm-jack-neary/venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"03/28/2023\" doesn't match format \"%Y-%m-%d\", at position 12. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "df_transform = df.copy()\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "df_transform = transform_types(df_transform, {\"enrollment_date\":\"datetime\"})\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "df_transform = transform_types(df_transform, {\n",
    "    \"site\":\"category\",\n",
    "    \"intervention_group\":\"category\",\n",
    "    \"sex\":\"category\"\n",
    "})\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "numeric_columns = [\n",
    "    \"age\", \"bmi\", \"systolic_bp\", \"diastolic_bp\",\n",
    "    \"cholesterol_total\", \"cholesterol_hdl\",\n",
    "    \"cholesterol_ldl\", \"glucose_fasting\"\n",
    "]\n",
    "df_transform = transform_types(df_transform, {col: \"numeric\" for col in numeric_columns})\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "display(df_transform.dtypes)\n",
    "\n",
    "print(df_transform.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate cholesterol ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Categorize blood pressure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create BMI categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: String cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One-hot encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save transformed data\n",
    "# df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
